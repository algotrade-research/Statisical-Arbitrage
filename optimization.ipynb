{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import os\n",
    "from statsmodels.tsa.api import AutoReg\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import time\n",
    "from datetime import timedelta,datetime\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    \"\"\"Handles stock data loading and clustering for statistical arbitrage.\n",
    "\n",
    "    Args:\n",
    "        futures (str): Futures ticker symbol (e.g., 'VN30F1M').\n",
    "        stocks (list): List of stock ticker symbols (excluding ETFs).\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        estimation_window (int, optional): Window size for residual computation. Defaults to 60.\n",
    "        cluster_update_interval (int, optional): Days between cluster updates. Defaults to 3.\n",
    "        futures_change_threshold (float, optional): Threshold for futures price change. Defaults to 0.05.\n",
    "        max_clusters (int, optional): Maximum number of clusters. Defaults to 10.\n",
    "        etf_list (list, optional): List of ETF ticker symbols. Defaults to None.\n",
    "        etf_included (bool, optional): Whether to include ETFs in clustering. Defaults to True.\n",
    "\n",
    "    Attributes:\n",
    "        futures (str): Futures ticker symbol.\n",
    "        stocks (list): List of stock ticker symbols (excluding ETFs).\n",
    "        start_date (str): Start date.\n",
    "        end_date (str): End date.\n",
    "        estimation_window (int): Window size for residuals.\n",
    "        cluster_update_interval (int): Days between cluster updates.\n",
    "        futures_change_threshold (float): Threshold for futures price change.\n",
    "        max_clusters (int): Maximum number of clusters.\n",
    "        etf_list (list): List of ETF ticker symbols.\n",
    "        etf_included (bool): Whether ETFs are included in clustering.\n",
    "        data (pd.DataFrame): Loaded price data.\n",
    "        last_clusters (list): Last computed clusters.\n",
    "        last_cluster_day (datetime): Date of last cluster update.\n",
    "        last_futures_price (float): Last futures price.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, futures, stocks, start_date, end_date, \n",
    "                 estimation_window=60, cluster_update_interval=3, \n",
    "                 futures_change_threshold=0.05, max_clusters=10,\n",
    "                 etf_list=None, etf_included=True):\n",
    "        self.futures = futures\n",
    "        # Ensure stocks list does not include ETFs\n",
    "        self.etf_list = etf_list if etf_list is not None else []\n",
    "        self.stocks = [s for s in stocks if s not in self.etf_list]  # Filter out ETFs from stocks\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.estimation_window = estimation_window\n",
    "        self.cluster_update_interval = cluster_update_interval\n",
    "        self.futures_change_threshold = futures_change_threshold\n",
    "        self.max_clusters = max_clusters\n",
    "        self.etf_included = etf_included\n",
    "        self.data = self.load_data()\n",
    "        self.last_clusters = None\n",
    "        self.last_cluster_day = None\n",
    "        self.last_futures_price = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load price data for futures, stocks, and optionally ETFs.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Cleaned price data with no missing values.\n",
    "        \"\"\"\n",
    "        # Load data for futures and stocks\n",
    "        symbols_to_load = [self.futures] + self.stocks\n",
    "        # If ETFs are included, add them to the symbols to load\n",
    "        if self.etf_included:\n",
    "            symbols_to_load.extend(self.etf_list)\n",
    "        data = get_stock_data(symbols_to_load, self.start_date, self.end_date)\n",
    "        return data.dropna()\n",
    "\n",
    "    def compute_residuals(self, window_data):\n",
    "        \"\"\"Compute residuals from OLS regression of stocks (and ETFs if included) against futures.\n",
    "\n",
    "        Args:\n",
    "            window_data (pd.DataFrame): Price data for the estimation window.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Residuals for each stock/ETF.\n",
    "        \"\"\"\n",
    "        residuals = pd.DataFrame(index=window_data.index)\n",
    "        # Compute residuals for stocks and ETFs (if included)\n",
    "        symbols = self.stocks\n",
    "        if self.etf_included:\n",
    "            symbols = symbols + self.etf_list\n",
    "        for symbol in symbols:\n",
    "            if symbol in window_data.columns:\n",
    "                X = sm.add_constant(window_data[self.futures])\n",
    "                y = window_data[symbol]\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                residuals[symbol] = model.resid\n",
    "        return residuals.dropna()\n",
    "\n",
    "    def cluster_stocks(self, window_data, current_day, futures_current_price):\n",
    "        \"\"\"Cluster stocks based on residuals using KMeans, with optional ETF handling.\n",
    "\n",
    "        Args:\n",
    "            window_data (pd.DataFrame): Price data for the estimation window.\n",
    "            current_day (datetime): Current date for clustering.\n",
    "            futures_current_price (float): Current futures price.\n",
    "\n",
    "        Returns:\n",
    "            list: List of stock clusters.\n",
    "        \"\"\"\n",
    "        if (self.last_clusters is not None and self.last_cluster_day is not None):\n",
    "            days_since_last_cluster = (current_day - self.last_cluster_day).days\n",
    "            futures_change = (abs(futures_current_price - self.last_futures_price) / \n",
    "                              self.last_futures_price if self.last_futures_price else 0)\n",
    "            if (days_since_last_cluster < self.cluster_update_interval and \n",
    "                futures_change < self.futures_change_threshold):\n",
    "                return self.last_clusters\n",
    "        \n",
    "        residuals = self.compute_residuals(window_data)\n",
    "        if residuals.empty or len(residuals.columns) < 2:\n",
    "            # If residuals are empty or too few symbols, return all symbols as one cluster\n",
    "            symbols = self.stocks\n",
    "            if self.etf_included:\n",
    "                symbols = symbols + self.etf_list\n",
    "            self.last_clusters = [symbols]\n",
    "        else:\n",
    "            # Separate ETFs and stocks based on etf_included flag\n",
    "            if self.etf_included:\n",
    "                # Include ETFs, but cluster them separately\n",
    "                etf_list = self.etf_list\n",
    "                stock_list = self.stocks  # Already filtered in __init__\n",
    "            else:\n",
    "                # Exclude ETFs entirely\n",
    "                etf_list = []\n",
    "                stock_list = self.stocks\n",
    "            \n",
    "            clusters = []\n",
    "            # Cluster non-ETFs\n",
    "            if stock_list:\n",
    "                X = residuals[stock_list].T\n",
    "                best_k = min(2, len(stock_list))  # Ensure at least 2 if possible\n",
    "                best_score = -1\n",
    "                for k in range(2, min(self.max_clusters + 1, len(stock_list))):\n",
    "                    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "                    if kmeans.n_clusters > 1:\n",
    "                        score = silhouette_score(X, kmeans.labels_)\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_k = k\n",
    "                kmeans = KMeans(n_clusters=best_k, random_state=0).fit(X)\n",
    "                stock_clusters = {i: [] for i in range(best_k)}\n",
    "                for stock, label in zip(stock_list, kmeans.labels_):\n",
    "                    stock_clusters[label].append(stock)\n",
    "                clusters.extend([c for c in stock_clusters.values() if c])\n",
    "            # Add ETFs as a separate cluster if included\n",
    "            if self.etf_included and etf_list:\n",
    "                clusters.append(etf_list)\n",
    "            \n",
    "            self.last_clusters = clusters\n",
    "        \n",
    "        self.last_cluster_day = current_day\n",
    "        self.last_futures_price = futures_current_price\n",
    "        return self.last_clusters\n",
    "\n",
    "class StatArbStrategy:    \n",
    "    \"\"\"A class to implement a statistical arbitrage strategy using cointegration.\n",
    "\n",
    "    This class identifies cointegrated combinations of futures and stocks, validates them,\n",
    "    and tracks active combinations over time to generate trading signals.\n",
    "\n",
    "    Args:\n",
    "        data_handler: An object handling data access (futures, stocks, and historical data).\n",
    "        min_trading_days (int, optional): Minimum trading days before re-evaluating a combination. Defaults to 45.\n",
    "        threshold (float, optional): Minimum beta threshold for stock inclusion. Defaults to 0.05.\n",
    "        max_stocks (int, optional): Maximum number of stocks in a combination. Defaults to 10.\n",
    "        confidence_level (int, optional): Confidence level for Johansen cointegration test. Defaults to 1.\n",
    "        adf_significance (float, optional): Significance level for ADF test. Defaults to 0.05.\n",
    "        correlation_threshold (float, optional): Threshold for residual correlation to avoid duplicates. Defaults to 0.6.\n",
    "        dynamic_threshold (bool, optional): Whether to dynamically adjust correlation threshold. Defaults to True.\n",
    "        residual_threshold (float, optional): Threshold for residual size relative to futures price. Defaults to 0.3.\n",
    "        improvement_threshold (float, optional): Minimum improvement in trace statistic for adding a stock. Defaults to 0.03.\n",
    "\n",
    "    Attributes:\n",
    "        active_combinations (list): List of currently active cointegrated combinations.\n",
    "        combination_id (int): Unique identifier for combinations.\n",
    "        results (list): List of results for each day and combination.\n",
    "        validation_cache (dict): Cache for validation results to avoid redundant computations.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_handler, min_trading_days=45, threshold=0.05,\n",
    "                 max_stocks=10, confidence_level=1, adf_significance=0.05,\n",
    "                 correlation_threshold=0.6, dynamic_threshold=True,\n",
    "                 residual_threshold=0.3, improvement_threshold=0.03):\n",
    "        self.data_handler = data_handler\n",
    "        self.futures = data_handler.futures\n",
    "        self.stocks = data_handler.stocks\n",
    "        self.estimation_window = data_handler.estimation_window\n",
    "        self.data = data_handler.data\n",
    "        self.min_trading_days = min_trading_days\n",
    "        self.threshold = threshold\n",
    "        self.max_stocks = max_stocks\n",
    "        self.confidence_level = confidence_level\n",
    "        self.confidence_level_joh_final = min(2, confidence_level + 1)\n",
    "        self.adf_significance = adf_significance\n",
    "        self.adf_significance_trading = min(0.1, 2 * adf_significance)\n",
    "        self.correlation_threshold = correlation_threshold\n",
    "        self.dynamic_threshold = dynamic_threshold\n",
    "        self.residual_threshold = residual_threshold\n",
    "        self.improvement_threshold = improvement_threshold\n",
    "        self.active_combinations = []\n",
    "        self.combination_id = 0\n",
    "        self.results = []\n",
    "        self.validation_cache = {}\n",
    "\n",
    "    def get_pairwise_candidates(self, window_data, stocks_pool):\n",
    "        \"\"\"Identifies stocks that are cointegrated with the futures using pairwise Johansen tests.\n",
    "\n",
    "        Args:\n",
    "            window_data (pd.DataFrame): Historical data for the estimation window.\n",
    "            stocks_pool (list): List of stock symbols to test for cointegration.\n",
    "\n",
    "        Returns:\n",
    "            list: Sorted list of stock symbols that are cointegrated with the futures, ranked by trace statistic.\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        for stock in stocks_pool:\n",
    "            try:\n",
    "                result = coint_johansen(window_data[[self.futures, stock]], det_order=1, k_ar_diff=1)\n",
    "                if result.lr1[0] > result.cvt[0, self.confidence_level]:\n",
    "                    candidates.append((stock, result.lr1[0]))\n",
    "            except Exception as e:\n",
    "                print(f\"Pairwise test failed for {stock}: {e}\")\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [stock for stock, _ in candidates]\n",
    "\n",
    "    def build_combination_greedy(self, window_data, candidates):\n",
    "        \"\"\"Greedily builds a cointegrated combination of stocks with the futures, trying multiple starting points.\n",
    "\n",
    "        Args:\n",
    "            window_data (pd.DataFrame): Historical data for the estimation window.\n",
    "            candidates (list): List of candidate stock symbols.\n",
    "\n",
    "        Returns:\n",
    "            list: List of selected stock symbols forming a cointegrated combination.\n",
    "        \"\"\"\n",
    "        if not candidates:\n",
    "            return []\n",
    "        best_selected = []\n",
    "        best_trace_stat = -np.inf\n",
    "        for start_stock in candidates[:3]:  # Try top 3 starting points\n",
    "            selected = [start_stock]\n",
    "            current_trace_stat = coint_johansen(window_data[[self.futures, start_stock]], det_order=1, k_ar_diff=1).lr1[0]\n",
    "            for stock in [s for s in candidates if s != start_stock]:\n",
    "                if len(selected) >= self.max_stocks:\n",
    "                    break\n",
    "                test_subset = selected + [stock]\n",
    "                try:\n",
    "                    result = coint_johansen(window_data[[self.futures] + test_subset], det_order=1, k_ar_diff=1)\n",
    "                    if result.lr1[0] <= result.cvt[0, self.confidence_level]:\n",
    "                        continue\n",
    "                    improvement = (result.lr1[0] - current_trace_stat) / current_trace_stat\n",
    "                    if improvement < self.improvement_threshold:    \n",
    "                        continue\n",
    "                    evec = result.evec[:, 0]\n",
    "                    betas = -evec[1:] / evec[0]\n",
    "                    if not all(beta >= 0 for beta in betas):\n",
    "                        continue\n",
    "                    selected.append(stock)\n",
    "                    current_trace_stat = result.lr1[0]\n",
    "                except Exception as e:\n",
    "                    print(f\"Combination test failed: {e}\")\n",
    "            if current_trace_stat > best_trace_stat:\n",
    "                best_trace_stat = current_trace_stat\n",
    "                best_selected = selected[:]\n",
    "        return best_selected\n",
    "\n",
    "    def validate_combination(self, window_data, selected):\n",
    "        \"\"\"Validates a combination by checking cointegration, beta positivity, stationarity, and residual size.\n",
    "\n",
    "        Args:\n",
    "            window_data (pd.DataFrame): Historical data for the estimation window.\n",
    "            selected (list): List of selected stock symbols.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (combination_params, adf_pvalue) where combination_params is a dict with intercept and betas,\n",
    "                   or (None, np.inf) if validation fails.\n",
    "        \"\"\"\n",
    "        comb_key = frozenset(selected)\n",
    "        if comb_key in self.validation_cache:\n",
    "            return self.validation_cache[comb_key]\n",
    "        try:\n",
    "            result = coint_johansen(window_data[[self.futures] + list(selected)], det_order=1, k_ar_diff=1)\n",
    "            if result.lr1[0] <= result.cvt[0, self.confidence_level_joh_final]:\n",
    "                self.validation_cache[comb_key] = (None, np.inf)\n",
    "                return None, np.inf\n",
    "            evec = result.evec[:, 0]\n",
    "            betas = -evec[1:] / evec[0]\n",
    "            if not all(beta >= 0 for beta in betas):\n",
    "                self.validation_cache[comb_key] = (None, np.inf)\n",
    "                return None, np.inf\n",
    "            \n",
    "            synthetic_portfolio = sum(window_data[s] * b for s, b in zip(selected, betas))\n",
    "            residuals = window_data[self.futures] - synthetic_portfolio\n",
    "            intercept = -residuals.mean()\n",
    "            adf_pvalue = adfuller(residuals)[1]\n",
    "            if adf_pvalue >= self.adf_significance:\n",
    "                self.validation_cache[comb_key] = (None, adf_pvalue)\n",
    "                return None, adf_pvalue\n",
    "            futures_avg = window_data[self.futures].mean()\n",
    "            if np.percentile(np.abs(residuals), 95) > self.residual_threshold * futures_avg:\n",
    "                self.validation_cache[comb_key] = (None, adf_pvalue)\n",
    "                return None, adf_pvalue\n",
    "            selected_betas = {s: b for s, b in zip(selected, betas) if abs(b) > self.threshold}\n",
    "            combination_params = {'intercept': intercept, 'betas': selected_betas}\n",
    "            self.validation_cache[comb_key] = (combination_params, adf_pvalue)\n",
    "            return combination_params, adf_pvalue\n",
    "        except Exception as e:\n",
    "            print(f\"Validation failed for {selected}: {e}\")\n",
    "            self.validation_cache[comb_key] = (None, np.inf)\n",
    "            return None, np.inf\n",
    "\n",
    "    def is_similar(self, new_residuals, existing_residuals):\n",
    "        \"\"\"Checks if two sets of residuals are similar based on correlation.\n",
    "\n",
    "        Args:\n",
    "            new_residuals (pd.Series): Residuals of a new combination.\n",
    "            existing_residuals (pd.Series): Residuals of an existing combination.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if residuals are similar (correlation above threshold), False otherwise.\n",
    "        \"\"\"\n",
    "        if len(new_residuals) != len(existing_residuals):\n",
    "            return False\n",
    "        corr, _ = pearsonr(new_residuals, existing_residuals)\n",
    "        return corr > self.correlation_threshold\n",
    "\n",
    "    def adjust_correlation_threshold(self):\n",
    "        \"\"\"Dynamically adjusts the correlation threshold based on the number of active combinations.\n",
    "\n",
    "        If there are fewer than 10 active combinations, increases the threshold; otherwise, decreases it.\n",
    "        \"\"\"\n",
    "        if self.dynamic_threshold:\n",
    "            if len(self.active_combinations) < 10:\n",
    "                self.correlation_threshold = min(0.8, self.correlation_threshold + 0.05)\n",
    "            else:\n",
    "                self.correlation_threshold = max(0.5, self.correlation_threshold - 0.05)\n",
    "\n",
    "    def run_strategy(self):\n",
    "        \"\"\"Runs the statistical arbitrage strategy over the entire dataset.\n",
    "\n",
    "        Identifies cointegrated combinations, validates them, and tracks residuals over time.\n",
    "        Updates active combinations and logs results.\n",
    "        \"\"\"\n",
    "        for day in range(self.estimation_window, len(self.data)):\n",
    "            estimation_data = self.data.iloc[day - self.estimation_window:day]\n",
    "            current_day = self.data.index[day]\n",
    "            futures_current_price = self.data.iloc[day][self.futures]\n",
    "            self.adjust_correlation_threshold()\n",
    "            clusters = self.data_handler.cluster_stocks(estimation_data, current_day, futures_current_price)\n",
    "\n",
    "            for cluster in clusters:\n",
    "                candidates = self.get_pairwise_candidates(estimation_data, cluster)\n",
    "                selected = self.build_combination_greedy(estimation_data, candidates)\n",
    "                if selected:\n",
    "                    params, new_adf_pvalue = self.validate_combination(estimation_data, selected)\n",
    "                    if params:\n",
    "                        self.add_combination_if_not_similar(params, new_adf_pvalue, estimation_data, current_day)\n",
    "\n",
    "            top_candidates = []\n",
    "            for cluster in clusters:\n",
    "                cluster_candidates = self.get_pairwise_candidates(estimation_data, cluster)[:3]\n",
    "                top_candidates.extend(cluster_candidates)\n",
    "            top_candidates = list(set(top_candidates))\n",
    "\n",
    "            if top_candidates:\n",
    "                cross_selected = self.build_combination_greedy(estimation_data, top_candidates)\n",
    "                if cross_selected:\n",
    "                    cross_params, cross_adf_pvalue = self.validate_combination(estimation_data, cross_selected)\n",
    "                    if cross_params:\n",
    "                        self.add_combination_if_not_similar(cross_params, cross_adf_pvalue, estimation_data, current_day)\n",
    "\n",
    "            all_candidates = self.get_pairwise_candidates(estimation_data, self.stocks)\n",
    "            cross_selected = self.build_combination_greedy(estimation_data, all_candidates)\n",
    "            if cross_selected:\n",
    "                cross_params, cross_adf_pvalue = self.validate_combination(estimation_data, cross_selected)\n",
    "                if cross_params:\n",
    "                    self.add_combination_if_not_similar(cross_params, cross_adf_pvalue, estimation_data, current_day)\n",
    "\n",
    "            for comb in self.active_combinations[:]:\n",
    "                if day < comb['start_day']:\n",
    "                    continue\n",
    "                comb['trading_days'] += 1\n",
    "                current_prices = self.data.iloc[day]\n",
    "                synthetic_portfolio = sum(current_prices[s] * b for s, b in comb['params']['betas'].items())\n",
    "                residual = current_prices[self.futures] - (comb['params']['intercept'] + synthetic_portfolio)\n",
    "                comb['all_residuals'].append(residual)\n",
    "                if comb['trading_days'] >= self.min_trading_days:\n",
    "                    recent_residuals = pd.Series(comb['all_residuals'][-self.estimation_window:])\n",
    "                    if adfuller(recent_residuals)[1] >= self.adf_significance_trading:\n",
    "                        self.active_combinations.remove(comb)\n",
    "                        continue\n",
    "                row = {\n",
    "                    'Date': current_day,\n",
    "                    'Combination_ID': comb['id'],\n",
    "                    'Residual': residual,\n",
    "                    'Total_Combinations': len(self.active_combinations),\n",
    "                    'Num_Stocks': len(comb['params']['betas']),\n",
    "                    'Is_Estimation': False,\n",
    "                    'Intercept': comb['params']['intercept'],\n",
    "                    **{f'Beta_{s}': b for s, b in comb['params']['betas'].items()}\n",
    "                }\n",
    "                self.results.append(row)\n",
    "\n",
    "    def add_combination_if_not_similar(self, params, new_adf_pvalue, estimation_data, current_day):\n",
    "        \"\"\"Adds a new combination if its residuals are not similar to existing ones.\n",
    "\n",
    "        Args:\n",
    "            params (dict): Parameters of the new combination (intercept and betas).\n",
    "            new_adf_pvalue (float): ADF p-value of the new combination's residuals.\n",
    "            estimation_data (pd.DataFrame): Historical data for the estimation window.\n",
    "            current_day (pd.Timestamp): Current date in the backtest.\n",
    "        \"\"\"\n",
    "        synthetic_portfolio = sum(estimation_data[s] * b for s, b in params['betas'].items())\n",
    "        residuals = estimation_data[self.futures] - (params['intercept'] + synthetic_portfolio)\n",
    "        similar_found = False\n",
    "        to_remove = []\n",
    "        for comb in self.active_combinations:\n",
    "            existing_residuals = pd.Series(comb['all_residuals'][-self.estimation_window:])\n",
    "            if self.is_similar(residuals, existing_residuals):\n",
    "                if comb['trading_days'] >= self.min_trading_days:\n",
    "                    existing_adf_pvalue = adfuller(existing_residuals)[1]\n",
    "                    if new_adf_pvalue < 0.5 * existing_adf_pvalue:\n",
    "                        to_remove.append(comb)\n",
    "                else:\n",
    "                    similar_found = True\n",
    "        for comb in to_remove:\n",
    "            self.active_combinations.remove(comb)\n",
    "        if not similar_found:\n",
    "            self.combination_id += 1\n",
    "            self.active_combinations.append({\n",
    "                'id': self.combination_id,\n",
    "                'params': params,\n",
    "                'start_day': self.data.index.get_loc(current_day),\n",
    "                'all_residuals': residuals.tolist(),\n",
    "                'trading_days': 0\n",
    "            })\n",
    "            for i, res in enumerate(residuals):\n",
    "                row = {\n",
    "                    'Date': estimation_data.index[i],\n",
    "                    'Combination_ID': self.combination_id,\n",
    "                    'Residual': res,\n",
    "                    'Total_Combinations': len(self.active_combinations),\n",
    "                    'Num_Stocks': len(params['betas']),\n",
    "                    'Is_Estimation': True,\n",
    "                    'Intercept': params['intercept'],\n",
    "                    **{f'Beta_{s}': b for s, b in params['betas'].items()}\n",
    "                }\n",
    "                self.results.append(row)\n",
    "            print(f\"\\n=== New Combination {self.combination_id} at {current_day.date()} ===\")\n",
    "            print(f\"VN30F1M = {params['intercept']:.3f} + \" + \" + \".join([f\"{b:.3f}*{s}\" for s, b in params['betas'].items()]))\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Returns the results of the strategy as a DataFrame and the stock price data.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (results_df, stock_price) where results_df is a DataFrame of results and stock_price is the price data.\n",
    "        \"\"\"\n",
    "        results_df = pd.DataFrame(self.results)\n",
    "        # Add all stocks to results_df with 0 betas for non-combination stocks\n",
    "        for stock in self.stocks:\n",
    "            beta_col = f'Beta_{stock}'\n",
    "            if beta_col not in results_df.columns:\n",
    "                results_df[beta_col] = 0.0\n",
    "        results_df = results_df.sort_values(by=['Combination_ID', 'Date'])\n",
    "        stock_price = self.data\n",
    "        return results_df, stock_price\n",
    "\n",
    "class SignalGenerator:\n",
    "    \"\"\"Generates trading signals by fitting an Ornstein-Uhlenbeck (OU) process to residuals.\n",
    "\n",
    "    Args:\n",
    "        residuals (pd.DataFrame): Pivot table of residuals with dates as index and combination IDs as columns.\n",
    "        ou_window (int, optional): Window size for fitting the OU process. Defaults to 60.\n",
    "        fallback_days (int, optional): Number of days to use previous OU parameters if fitting fails. Defaults to 5.\n",
    "\n",
    "    Attributes:\n",
    "        ou_params (pd.DataFrame): DataFrame storing OU parameters (kappa, m, sigma, s_score) for each combination.\n",
    "        last_valid_params (dict): Stores the last valid OU parameters for each combination.\n",
    "        ou_cache (dict): Cache for OU fitting results to avoid redundant computations.\n",
    "    \"\"\"\n",
    "    def __init__(self, residuals: pd.DataFrame, ou_window: int = 60, fallback_days: int = 5):\n",
    "        self.residuals = residuals\n",
    "        self.ou_window = ou_window\n",
    "        self.fallback_days = fallback_days\n",
    "        self.ou_params = None\n",
    "        self.last_valid_params = {col: None for col in residuals.columns}\n",
    "        self.ou_cache = {}\n",
    "\n",
    "    def fit_ou_process(self, series: pd.Series, date: pd.Timestamp) -> Dict[str, float]:\n",
    "        \"\"\"Fits an Ornstein-Uhlenbeck process to a series of residuals and computes the s-score.\n",
    "\n",
    "        Args:\n",
    "            series (pd.Series): Residual series for a combination.\n",
    "            date (pd.Timestamp): Current date for caching purposes.\n",
    "\n",
    "        Returns:\n",
    "            dict: OU parameters {'kappa': float, 'm': float, 'sigma': float, 's_score': float}.\n",
    "                  Returns NaN values if fitting fails.\n",
    "        \"\"\"\n",
    "        cache_key = (series.name, date)\n",
    "        if cache_key in self.ou_cache:\n",
    "            return self.ou_cache[cache_key]\n",
    "        if len(series) < self.ou_window:\n",
    "            return {'kappa': np.nan, 'm': np.nan, 'sigma': np.nan, 's_score': np.nan}\n",
    "        series_window = series[-self.ou_window:].dropna().to_numpy()\n",
    "        if len(series_window) < self.ou_window:\n",
    "            return {'kappa': np.nan, 'm': np.nan, 'sigma': np.nan, 's_score': np.nan}\n",
    "        try:\n",
    "            model = AutoReg(series_window, lags=1).fit()\n",
    "            a, b = model.params\n",
    "            p_value_b = model.pvalues[1]\n",
    "            if p_value_b >= 0.10 or b <= 0 or b >= 1:\n",
    "                return {'kappa': np.nan, 'm': np.nan, 'sigma': np.nan, 's_score': np.nan}\n",
    "            kappa = -np.log(b) * np.sqrt(252)\n",
    "            m = a / (1 - b)\n",
    "            sigma = np.sqrt(model.sigma2 * 2 * kappa / (1 - b**2))\n",
    "            latest = series.iloc[-1]\n",
    "            sigma_eq = sigma / np.sqrt(2 * kappa) if kappa > 0 else np.inf\n",
    "            s_score = (latest - m) / sigma_eq if sigma_eq != 0 else 0\n",
    "            params = {'kappa': kappa, 'm': m, 'sigma': sigma, 's_score': s_score}\n",
    "            self.ou_cache[cache_key] = params\n",
    "            return params\n",
    "        except (ValueError, np.linalg.LinAlgError):\n",
    "            return {'kappa': np.nan, 'm': np.nan, 'sigma': np.nan, 's_score': np.nan}\n",
    "\n",
    "    def apply_ou_fitting(self):\n",
    "        \"\"\"Applies OU process fitting to all residual series over time.\n",
    "\n",
    "        Updates the ou_params DataFrame with kappa, m, sigma, and s_score for each combination and date.\n",
    "        \"\"\"\n",
    "        columns = pd.MultiIndex.from_product([self.residuals.columns, ['kappa', 'm', 'sigma', 's_score']])\n",
    "        self.ou_params = pd.DataFrame(index=self.residuals.index, columns=columns)\n",
    "        for t in range(self.ou_window, len(self.residuals)):\n",
    "            date = self.residuals.index[t]\n",
    "            for stock in self.residuals.columns:\n",
    "                series = self.residuals[stock].iloc[:t + 1]\n",
    "                params = self.fit_ou_process(series, date)\n",
    "                if not np.isnan(params['kappa']):\n",
    "                    self.last_valid_params[stock] = {'params': params, 'date': date}\n",
    "                elif self.last_valid_params[stock] and (date - self.last_valid_params[stock]['date']).days <= self.fallback_days:\n",
    "                    last_params = self.last_valid_params[stock]['params']\n",
    "                    latest = series.iloc[-1]\n",
    "                    m, kappa, sigma = last_params['m'], last_params['kappa'], last_params['sigma']\n",
    "                    sigma_eq = sigma / np.sqrt(2 * kappa) if kappa > 0 else np.inf\n",
    "                    params['s_score'] = (latest - m) / sigma_eq if sigma_eq != 0 else 0\n",
    "                for param, value in params.items():\n",
    "                    self.ou_params.loc[date, (stock, param)] = value\n",
    "\n",
    "def get_allocation_tier(s_score: float, prev_allocation: float, prev_s_score: float, is_decreasing_trend: bool) -> float:\n",
    "    \"\"\"Determines the allocation tier based on the s-score and trend.\n",
    "\n",
    "    Args:\n",
    "        s_score (float): Current s-score from the OU process.\n",
    "        prev_allocation (float): Previous allocation percentage.\n",
    "        prev_s_score (float): Previous s-score.\n",
    "        is_decreasing_trend (bool): Whether the s-score is decreasing.\n",
    "\n",
    "    Returns:\n",
    "        float: Allocation percentage for the current s-score tier.\n",
    "    \"\"\"\n",
    "    if s_score > 2.0 or s_score < -1.5:\n",
    "        return 0.0\n",
    "    elif s_score > 1.5 and s_score > prev_s_score:\n",
    "        return 1.2\n",
    "    elif s_score > 1.25 and s_score > prev_s_score:\n",
    "        return 1\n",
    "    elif s_score > 1.0: \n",
    "        return 0.8\n",
    "    elif prev_allocation > 0:\n",
    "        if s_score < 1.0 and s_score < prev_s_score:\n",
    "            return max(0.0, prev_allocation - 0.1)\n",
    "        elif s_score > prev_s_score and is_decreasing_trend:\n",
    "            return max(0.0, prev_allocation - 0.2)\n",
    "        else:\n",
    "            return prev_allocation\n",
    "    return 0.0\n",
    "\n",
    "def generate_signals(residuals_pivot: pd.DataFrame, ou_window: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Generates OU-based trading signals from residuals.\n",
    "\n",
    "    Args:\n",
    "        residuals_pivot (pd.DataFrame): Pivot table of residuals with dates as index and combination IDs as columns.\n",
    "        ou_window (int, optional): Window size for OU process fitting. Defaults to 60.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with OU parameters (kappa, m, sigma, s_score) for each combination and date.\n",
    "    \"\"\"\n",
    "    signal_gen = SignalGenerator(residuals_pivot, ou_window=ou_window)\n",
    "    signal_gen.apply_ou_fitting()\n",
    "    return signal_gen.ou_params\n",
    "\n",
    "def compute_allocations(ou_params: pd.DataFrame, residuals_pivot: pd.DataFrame, ou_window: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"Computes allocation percentages based on OU s-scores.\n",
    "\n",
    "    Args:\n",
    "        ou_params (pd.DataFrame): DataFrame with OU parameters (kappa, m, sigma, s_score).\n",
    "        residuals_pivot (pd.DataFrame): Pivot table of residuals.\n",
    "        ou_window (int, optional): Window size for OU process fitting. Defaults to 60.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with allocation percentages for each combination and date.\n",
    "    \"\"\"\n",
    "    allocation_percentages = pd.DataFrame(index=ou_params.index, columns=residuals_pivot.columns, dtype=float).fillna(0.0)\n",
    "    trend_tracker = {comb_id: False for comb_id in residuals_pivot.columns}\n",
    "\n",
    "    for comb_id in allocation_percentages.columns:\n",
    "        s_scores = ou_params[(comb_id, 's_score')]\n",
    "        prev_allocation = 0.0\n",
    "        prev_s_score = np.nan\n",
    "        for i, date in enumerate(s_scores.index):\n",
    "            if i < ou_window:\n",
    "                allocation = 0.0\n",
    "            else:\n",
    "                s_score = s_scores[date]\n",
    "                if pd.isna(s_score) or pd.isna(residuals_pivot.loc[date, comb_id]):\n",
    "                    allocation = 0.0\n",
    "                else:\n",
    "                    is_decreasing = s_score < prev_s_score if not pd.isna(prev_s_score) else False\n",
    "                    trend_tracker[comb_id] = is_decreasing\n",
    "                    allocation = get_allocation_tier(s_score, prev_allocation, prev_s_score, trend_tracker[comb_id])\n",
    "                    prev_s_score = s_score if not pd.isna(s_score) else prev_s_score\n",
    "            allocation_percentages.loc[date, comb_id] = allocation\n",
    "            prev_allocation = allocation\n",
    "    return allocation_percentages\n",
    "\n",
    "def calculate_positions(allocation_percentages: pd.DataFrame, results_df: pd.DataFrame, stock_price: pd.DataFrame, stocks: list) -> pd.DataFrame:\n",
    "    \"\"\"Calculates trading positions based on allocation percentages.\n",
    "\n",
    "    Args:\n",
    "        allocation_percentages (pd.DataFrame): DataFrame with allocation percentages.\n",
    "        results_df (pd.DataFrame): DataFrame with combination results (betas, residuals, etc.).\n",
    "        stock_price (pd.DataFrame): DataFrame with stock and futures prices.\n",
    "        stocks (list): List of stock symbols.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with positions for VN30F1M and each stock, including absolute values.\n",
    "    \"\"\"\n",
    "    dates = results_df['Date'].sort_values().unique()\n",
    "    columns = ['Total_Port_Trading', 'VN30F1M_Position'] + [f'{stock}_Position' for stock in stocks] + ['Num_Active_Combinations', 'Active_Combination_IDs']\n",
    "    positions_df = pd.DataFrame(index=dates, columns=columns, dtype=float)\n",
    "    positions_df['Active_Combination_IDs'] = positions_df['Active_Combination_IDs'].astype(object)\n",
    "    positions_df = positions_df.fillna(0.0)\n",
    "\n",
    "    for date in dates:\n",
    "        if date not in allocation_percentages.index:\n",
    "            continue\n",
    "        active_combs = allocation_percentages.loc[date][allocation_percentages.loc[date] > 0]\n",
    "        num_active = len(active_combs)\n",
    "        active_ids = list(active_combs.index)\n",
    "        positions_df.loc[date, 'Num_Active_Combinations'] = num_active\n",
    "        positions_df.loc[date, 'Active_Combination_IDs'] = str(active_ids)\n",
    "\n",
    "        if num_active == 0:\n",
    "            total_allocation = 0.0\n",
    "        else:\n",
    "            base_allocation = min(0.6 + 0.1 * (num_active - 1), 1.0)\n",
    "            intended_allocations = active_combs * base_allocation\n",
    "            total_intended = intended_allocations.sum()\n",
    "            scale_factor = 1.0 / total_intended if total_intended > 1.0 else 1.0\n",
    "            scaled_allocations = intended_allocations * scale_factor\n",
    "            total_allocation = scaled_allocations.sum()\n",
    "\n",
    "        positions_df.loc[date, 'Total_Port_Trading'] = total_allocation\n",
    "        positions_df.loc[date, 'VN30F1M_Position'] = -total_allocation * 0.20  # 20% short\n",
    "\n",
    "        stock_allocation = total_allocation * 0.80  # 80% to stocks\n",
    "        for comb_id in active_combs.index:\n",
    "            comb_allocation = scaled_allocations[comb_id] * stock_allocation / total_allocation if total_allocation > 0 else 0\n",
    "            comb_row = results_df[(results_df['Date'] == date) & (results_df['Combination_ID'] == comb_id)]\n",
    "            if comb_row.empty or date not in stock_price.index:\n",
    "                continue\n",
    "\n",
    "            comb_stocks = [s for s in stocks if f'Beta_{s}' in comb_row.columns and comb_row[f'Beta_{s}'].values[0] >= 0]\n",
    "            sum_beta_price = 0.0\n",
    "            valid_comb_stocks = []\n",
    "            for s in comb_stocks:\n",
    "                beta = comb_row[f'Beta_{s}'].values[0]\n",
    "                price = stock_price.loc[date, s] if s in stock_price.columns and not pd.isna(stock_price.loc[date, s]) else np.nan\n",
    "                if not pd.isna(price):\n",
    "                    sum_beta_price += beta * price\n",
    "                    valid_comb_stocks.append(s)\n",
    "\n",
    "            if sum_beta_price > 0:\n",
    "                for stock in valid_comb_stocks:\n",
    "                    beta = comb_row[f'Beta_{stock}'].values[0]\n",
    "                    current_price = stock_price.loc[date, stock]\n",
    "                    stock_proportion = (beta * current_price) / sum_beta_price\n",
    "                    stock_position = comb_allocation * stock_proportion\n",
    "                    positions_df.loc[date, f'{stock}_Position'] += stock_position\n",
    "\n",
    "    return positions_df\n",
    "\n",
    "def process_results_df(results_df: pd.DataFrame, stock_price: pd.DataFrame, stocks: list, ou_window: int = 60) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Processes the results DataFrame to generate signals, allocations, positions, and trading logs.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame with combination results.\n",
    "        stock_price (pd.DataFrame): DataFrame with stock and futures prices.\n",
    "        stocks (list): List of stock symbols.\n",
    "        ou_window (int, optional): Window size for OU process fitting. Defaults to 60.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (results_df, positions_df, trading_log) where:\n",
    "            - results_df: Updated results with s-scores and allocations.\n",
    "            - positions_df: DataFrame with trading positions.\n",
    "            - trading_log: DataFrame with trading actions and deltas.\n",
    "    \"\"\"\n",
    "    results_df = results_df.sort_values('Date')\n",
    "    residuals_pivot = results_df.pivot(index='Date', columns='Combination_ID', values='Residual')\n",
    "    ou_params = generate_signals(residuals_pivot, ou_window=ou_window)\n",
    "    allocation_percentages = compute_allocations(ou_params, residuals_pivot, ou_window=ou_window)\n",
    "    positions_df = calculate_positions(allocation_percentages, results_df, stock_price, stocks)\n",
    "\n",
    "    # Add s-scores and allocations to results_df\n",
    "    results_df['s_score'] = results_df.apply(\n",
    "        lambda row: ou_params.loc[row['Date'], (row['Combination_ID'], 's_score')]\n",
    "        if row['Date'] in ou_params.index else np.nan, axis=1\n",
    "    )\n",
    "    results_df['Allocation'] = results_df.apply(\n",
    "        lambda row: allocation_percentages.loc[row['Date'], row['Combination_ID']]\n",
    "        if row['Date'] in allocation_percentages.index else 0.0, axis=1\n",
    "    )\n",
    "\n",
    "    # Add absolute values to positions_df\n",
    "    for date in positions_df.index:\n",
    "        if date in stock_price.index and not pd.isna(stock_price.loc[date, 'VN30F1M']):\n",
    "            vn30_pos = positions_df.loc[date, 'VN30F1M_Position']\n",
    "            positions_df.loc[date, 'Abs_VN30F1M'] = abs(vn30_pos) * stock_price.loc[date, 'VN30F1M']\n",
    "            total_abs_stocks = 0.0\n",
    "            for stock in stocks:\n",
    "                stock_pos = positions_df.loc[date, f'{stock}_Position']\n",
    "                if stock_pos > 0:\n",
    "                    stock_price_val = stock_price.loc[date, stock]\n",
    "                    positions_df.loc[date, f'Abs_{stock}'] = stock_pos * stock_price_val\n",
    "                    total_abs_stocks += stock_pos * stock_price_val\n",
    "                else:\n",
    "                    positions_df.loc[date, f'Abs_{stock}'] = 0.0\n",
    "            positions_df.loc[date, 'Abs_Stocks'] = total_abs_stocks\n",
    "        else:\n",
    "            positions_df.loc[date, 'Abs_VN30F1M'] = np.nan\n",
    "            positions_df.loc[date, 'Abs_Stocks'] = np.nan\n",
    "            for stock in stocks:\n",
    "                positions_df.loc[date, f'Abs_{stock}'] = np.nan\n",
    "\n",
    "    # Generate trading log\n",
    "    trading_log = pd.DataFrame(index=positions_df.index)\n",
    "    trading_log['Total_Port_Trading'] = positions_df['Total_Port_Trading']\n",
    "    trading_log['Delta_VN30F1M'] = positions_df['VN30F1M_Position'].diff().fillna(0.0)\n",
    "    trading_log['Action_VN30F1M'] = np.where(\n",
    "        (trading_log['Delta_VN30F1M'] > 0) & (positions_df['VN30F1M_Position'].shift(1).fillna(0.0) < 0), 'buy to cover',\n",
    "        np.where(trading_log['Delta_VN30F1M'] < 0, 'sell short', 'hold')\n",
    "    )\n",
    "    for stock in stocks:\n",
    "        pos_col = f'{stock}_Position'\n",
    "        delta_col = f'Delta_{stock}'\n",
    "        action_col = f'Action_{stock}'\n",
    "        trading_log[delta_col] = positions_df[pos_col].diff().fillna(0.0)\n",
    "        trading_log[action_col] = np.where(\n",
    "            trading_log[delta_col] > 0, 'buy',\n",
    "            np.where(trading_log[delta_col] < 0, 'sell', 'hold')\n",
    "        )\n",
    "    trading_log['Num_Active_Combinations'] = positions_df['Num_Active_Combinations']\n",
    "    trading_log['Active_Combination_IDs'] = positions_df['Active_Combination_IDs']\n",
    "\n",
    "    # Round values\n",
    "    for df in [positions_df, trading_log]:\n",
    "        for col in df.columns:\n",
    "            if col.startswith(('Total_Port_Trading', 'VN30F1M_Position', 'Delta_VN30F1M', 'Abs_VN30F1M', 'Abs_Stocks')) or col.endswith('_Position') or col.startswith('Delta_') or col.startswith('Abs_'):\n",
    "                df[col] = df[col].apply(lambda x: round(x, 4) if pd.notna(x) and abs(x) > 1e-10 else 0.0)\n",
    "\n",
    "    # Sort indices\n",
    "    results_df.sort_values(by=['Combination_ID', 'Date'], inplace=True)\n",
    "    positions_df.sort_index(inplace=True)\n",
    "    trading_log.sort_index(inplace=True)\n",
    "\n",
    "    return results_df, positions_df, trading_log\n",
    "class PortfolioManager:\n",
    "    \"\"\"Manages a portfolio for backtesting a trading strategy with futures and stocks.\n",
    "\n",
    "    Handles position adjustments, margin requirements, and profit calculations for VN30F1M futures and stocks.\n",
    "\n",
    "    Args:\n",
    "        initial_balance (float, optional): Initial cash balance. Defaults to 1,000,000,000.\n",
    "        vn30_fee_per_point (float, optional): Fee per point for VN30F1M futures. Defaults to 0.23.\n",
    "        stock_fee_rate (float, optional): Fee rate for stock transactions. Defaults to 0.0023.\n",
    "        margin_initial (float, optional): Initial margin requirement for futures. Defaults to 0.25.\n",
    "        contract_size (int, optional): Contract size for futures and stock lots. Defaults to 100.\n",
    "        min_cash_fraction (float, optional): Minimum cash fraction of initial balance. Defaults to 0.02.\n",
    "        estimation_window (int, optional): Number of days to ignore for pair searching. Defaults to 60.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_balance: float = 1000000000, vn30_fee_per_point: float = 0.23, \n",
    "                 stock_fee_rate: float = 0.0023, margin_initial: float = 0.25, contract_size: int = 100,\n",
    "                 min_cash_fraction: float = 0.02, estimation_window: int = 60):\n",
    "        self.initial_balance = initial_balance\n",
    "        self.vn30_fee_per_point = vn30_fee_per_point\n",
    "        self.stock_fee_rate = stock_fee_rate\n",
    "        self.margin_initial = margin_initial\n",
    "        self.contract_size = contract_size\n",
    "        self.min_cash_fraction = min_cash_fraction\n",
    "        self.estimation_window = estimation_window\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the portfolio to its initial state.\"\"\"\n",
    "        self.cash = self.initial_balance\n",
    "        self.positions = {'VN30F1M': 0}\n",
    "        self.stock_positions = {}\n",
    "        self.margin_posted = 0\n",
    "        self.realized_profit = 0\n",
    "        self.entry_prices = {'VN30F1M': []}\n",
    "        self.stock_entry_prices = {}\n",
    "        self.prev_positions = {'VN30F1M': 0}\n",
    "        self.prev_stock_positions = {}\n",
    "        self.prev_vn30_price = None\n",
    "        self.prev_stock_prices = {}\n",
    "        self.prev_balance = self.initial_balance\n",
    "        self.cumulative_profit_stocks = 0.0\n",
    "        self.cumulative_profit_futures = 0.0\n",
    "        self.asset_df = []\n",
    "        self.detail_df = []\n",
    "        self.trading_log = []\n",
    "\n",
    "    def _calculate_initial_margin(self, price: float, contracts: int) -> float:\n",
    "        \"\"\"Calculates the initial margin required for a futures position.\"\"\"\n",
    "        return self.margin_initial * price * self.contract_size * abs(contracts)\n",
    "\n",
    "    def get_portfolio_value(self, vn30f1m_price: float, stock_prices: Dict[str, float]) -> float:\n",
    "        \"\"\"Calculates the total portfolio value.\"\"\"\n",
    "        stocks_value = sum(self.stock_positions.get(stock, 0) * stock_prices.get(stock, 0) \n",
    "                           for stock in self.stock_positions if not np.isnan(stock_prices.get(stock, 0)))\n",
    "        if self.positions['VN30F1M'] != 0 and not np.isnan(vn30f1m_price):\n",
    "            avg_entry = sum(self.entry_prices['VN30F1M']) / len(self.entry_prices['VN30F1M']) if self.entry_prices['VN30F1M'] else 0\n",
    "            unrealized_futures = (vn30f1m_price - avg_entry) * self.positions['VN30F1M'] * self.contract_size\n",
    "        else:\n",
    "            unrealized_futures = 0\n",
    "        return self.cash + stocks_value + self.margin_posted + unrealized_futures\n",
    "\n",
    "    def adjust_vn30f1m_position(self, date: pd.Timestamp, price: float, delta: float, portfolio_value: float, \n",
    "                                daily_fee: float, realized_futures_last_day: float) -> Tuple[float, float, int]:\n",
    "        \"\"\"Adjusts the VN30F1M futures position based on the delta signal.\"\"\"\n",
    "        contracts_traded = 0\n",
    "        if delta == 0:\n",
    "            return daily_fee, realized_futures_last_day, contracts_traded\n",
    "        fee_per_contract = self.vn30_fee_per_point * self.contract_size\n",
    "        min_cash = self.min_cash_fraction * self.initial_balance\n",
    "\n",
    "        if delta < 0:  # Sell short\n",
    "            notional_to_short = (portfolio_value * abs(delta)) / self.margin_initial\n",
    "            contracts_to_sell = int(notional_to_short / (self.contract_size * price))\n",
    "            if contracts_to_sell > 0:\n",
    "                margin_new = self._calculate_initial_margin(price, contracts_to_sell)\n",
    "                fee = contracts_to_sell * fee_per_contract\n",
    "                total_cost = margin_new + fee\n",
    "                if self.cash - total_cost >= min_cash:\n",
    "                    self.cash -= total_cost\n",
    "                    self.margin_posted += margin_new\n",
    "                    self.positions['VN30F1M'] -= contracts_to_sell\n",
    "                    self.entry_prices['VN30F1M'].extend([price] * contracts_to_sell)\n",
    "                    daily_fee += fee\n",
    "                    contracts_traded -= contracts_to_sell\n",
    "                else:\n",
    "                    max_contracts = int((self.cash - min_cash) / (self.margin_initial * price * self.contract_size + fee_per_contract))\n",
    "                    contracts_to_sell = min(contracts_to_sell, max_contracts) if max_contracts > 0 else 0\n",
    "                    if contracts_to_sell > 0:\n",
    "                        margin_new = self._calculate_initial_margin(price, contracts_to_sell)\n",
    "                        fee = contracts_to_sell * fee_per_contract\n",
    "                        self.cash -= (margin_new + fee)\n",
    "                        self.margin_posted += margin_new\n",
    "                        self.positions['VN30F1M'] -= contracts_to_sell\n",
    "                        self.entry_prices['VN30F1M'].extend([price] * contracts_to_sell)\n",
    "                        daily_fee += fee\n",
    "                        contracts_traded -= contracts_to_sell\n",
    "        elif delta > 0:  # Buy to cover\n",
    "            contracts_to_buy = int((portfolio_value * delta) / (self.contract_size * price))\n",
    "            if contracts_to_buy > 0 and self.positions['VN30F1M'] < 0:\n",
    "                contracts_to_buy = min(contracts_to_buy, abs(self.positions['VN30F1M']))\n",
    "                margin_released = self._calculate_initial_margin(price, contracts_to_buy)\n",
    "                fee = contracts_to_buy * fee_per_contract\n",
    "                self.cash += margin_released - fee\n",
    "                self.margin_posted -= margin_released\n",
    "                entry_prices_to_close = self.entry_prices['VN30F1M'][:contracts_to_buy]\n",
    "                realized_pnl = sum((entry - price) * self.contract_size for entry in entry_prices_to_close)\n",
    "                self.realized_profit += realized_pnl\n",
    "                realized_futures_last_day += realized_pnl\n",
    "                self.positions['VN30F1M'] += contracts_to_buy\n",
    "                self.entry_prices['VN30F1M'] = self.entry_prices['VN30F1M'][contracts_to_buy:]\n",
    "                daily_fee += fee\n",
    "                contracts_traded += contracts_to_buy\n",
    "\n",
    "        return daily_fee, realized_futures_last_day, contracts_traded\n",
    "\n",
    "    def adjust_stock_position(self, date: pd.Timestamp, stock: str, price: float, delta: float, portfolio_value: float, \n",
    "                              daily_fee: float, realized_stocks_last_day: float) -> Tuple[float, float, int]:\n",
    "        \"\"\"Adjusts the position of a stock based on the delta signal.\"\"\"\n",
    "        shares_traded = 0\n",
    "        if delta == 0:\n",
    "            return daily_fee, realized_stocks_last_day, shares_traded\n",
    "        min_cash = self.min_cash_fraction * self.initial_balance\n",
    "\n",
    "        if delta > 0:  # Buy\n",
    "            shares_to_buy = int((portfolio_value * delta) / price)\n",
    "            lots_to_buy = max(shares_to_buy // self.contract_size, 1)  # Ensure at least 1 lot if delta > 0\n",
    "            shares_to_buy = lots_to_buy * self.contract_size\n",
    "            cost = shares_to_buy * price\n",
    "            fee = cost * self.stock_fee_rate\n",
    "            total_cost = cost + fee\n",
    "            if self.cash - total_cost >= min_cash:\n",
    "                self.cash -= total_cost\n",
    "                if stock not in self.stock_positions:\n",
    "                    self.stock_positions[stock] = 0\n",
    "                    self.stock_entry_prices[stock] = 0\n",
    "                total_shares = self.stock_positions[stock] + shares_to_buy\n",
    "                total_cost_entry = self.stock_entry_prices[stock] * self.stock_positions[stock] + price * shares_to_buy\n",
    "                self.stock_entry_prices[stock] = total_cost_entry / total_shares if total_shares > 0 else 0\n",
    "                self.stock_positions[stock] = total_shares\n",
    "                shares_traded += shares_to_buy\n",
    "                daily_fee += fee\n",
    "            else:\n",
    "                max_shares = int((self.cash - min_cash) / (price * (1 + self.stock_fee_rate)))\n",
    "                max_lots = max(max_shares // self.contract_size, 1) if max_shares >= self.contract_size else 0\n",
    "                shares_to_buy = max_lots * self.contract_size\n",
    "                if shares_to_buy > 0:\n",
    "                    cost = shares_to_buy * price\n",
    "                    fee = cost * self.stock_fee_rate\n",
    "                    total_cost = cost + fee\n",
    "                    self.cash -= total_cost\n",
    "                    if stock not in self.stock_positions:\n",
    "                        self.stock_positions[stock] = 0\n",
    "                        self.stock_entry_prices[stock] = 0\n",
    "                    total_shares = self.stock_positions[stock] + shares_to_buy\n",
    "                    total_cost_entry = self.stock_entry_prices[stock] * self.stock_positions[stock] + price * shares_to_buy\n",
    "                    self.stock_entry_prices[stock] = total_cost_entry / total_shares if total_shares > 0 else 0\n",
    "                    self.stock_positions[stock] = total_shares\n",
    "                    shares_traded += shares_to_buy\n",
    "                    daily_fee += fee\n",
    "\n",
    "        elif delta < 0:  # Sell\n",
    "            shares_to_sell = int((portfolio_value * abs(delta)) / price)\n",
    "            lots_to_sell = max(shares_to_sell // self.contract_size, 1)  # Ensure at least 1 lot if delta < 0\n",
    "            shares_to_sell = min(lots_to_sell * self.contract_size, self.stock_positions.get(stock, 0))\n",
    "            if shares_to_sell > 0:\n",
    "                proceeds = shares_to_sell * price\n",
    "                fee = proceeds * self.stock_fee_rate\n",
    "                self.cash += proceeds - fee\n",
    "                realized_pnl = (price - self.stock_entry_prices[stock]) * shares_to_sell - fee\n",
    "                self.realized_profit += realized_pnl\n",
    "                realized_stocks_last_day += realized_pnl\n",
    "                self.stock_positions[stock] -= shares_to_sell\n",
    "                if self.stock_positions[stock] == 0:\n",
    "                    del self.stock_positions[stock]\n",
    "                    del self.stock_entry_prices[stock]\n",
    "                shares_traded -= shares_to_sell\n",
    "                daily_fee += fee\n",
    "\n",
    "        return daily_fee, realized_stocks_last_day, shares_traded\n",
    "\n",
    "    def run_backtest(self, trading_log: pd.DataFrame, prices: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Runs a backtest of the portfolio using the trading log and price data.\"\"\"\n",
    "        trading_log.index = pd.to_datetime(trading_log.index)\n",
    "        prices.index = pd.to_datetime(prices.index)\n",
    "        common_dates = trading_log.index.intersection(prices.index)\n",
    "        trading_log = trading_log.loc[common_dates]\n",
    "        prices = prices.loc[common_dates]\n",
    "\n",
    "        stocks = [col.replace('Delta_', '') for col in trading_log.columns if col.startswith('Delta_') and col != 'Delta_VN30F1M']\n",
    "        prev_vn30_price = None\n",
    "        prev_stock_prices = {stock: None for stock in stocks}\n",
    "        prev_positions = {'VN30F1M': 0}\n",
    "        prev_stock_positions = {stock: 0 for stock in stocks}\n",
    "        abs_stocks_prev = 0.0  # Initialize previous day's stock notional value\n",
    "\n",
    "        for day, date in enumerate(common_dates):\n",
    "            vn30_price = prices.loc[date, 'VN30F1M'] if 'VN30F1M' in prices.columns else np.nan\n",
    "            stock_prices = {stock: prices.loc[date, stock] if stock in prices.columns else np.nan for stock in stocks}\n",
    "            daily_fee = 0.0\n",
    "            realized_stocks_last_day = 0.0\n",
    "            realized_futures_last_day = 0.0\n",
    "            contracts_traded_vn30 = 0\n",
    "            shares_traded = {stock: 0 for stock in stocks}\n",
    "\n",
    "            # Calculate daily P/L based on previous day's positions\n",
    "            profit_stocks_last_day = sum((stock_prices[stock] - prev_stock_prices[stock]) * prev_stock_positions[stock]\n",
    "                                        for stock in stocks if prev_stock_prices[stock] is not None and not np.isnan(prev_stock_prices[stock]) and not np.isnan(stock_prices[stock]))\n",
    "            profit_futures_last_day = ((vn30_price - prev_vn30_price) * prev_positions['VN30F1M'] * self.contract_size\n",
    "                                      if prev_vn30_price is not None and not np.isnan(prev_vn30_price) and not np.isnan(vn30_price) else 0)\n",
    "\n",
    "            # Portfolio value before trading\n",
    "            portfolio_value = self.get_portfolio_value(vn30_price, stock_prices)\n",
    "\n",
    "            # Adjust VN30F1M position\n",
    "            delta_vn30 = trading_log.loc[date, 'Delta_VN30F1M']\n",
    "            if not np.isnan(vn30_price) and vn30_price > 0 and not pd.isna(delta_vn30):\n",
    "                daily_fee, realized_futures_last_day, contracts_traded_vn30 = self.adjust_vn30f1m_position(\n",
    "                    date, vn30_price, delta_vn30, portfolio_value, daily_fee, realized_futures_last_day)\n",
    "\n",
    "            # Adjust stock positions\n",
    "            for stock in stocks:\n",
    "                delta_stock = trading_log.loc[date, f'Delta_{stock}']\n",
    "                price = stock_prices.get(stock)\n",
    "                if price is not None and not np.isnan(price) and price > 0 and not pd.isna(delta_stock):\n",
    "                    daily_fee, realized_stocks_last_day, shares_traded[stock] = self.adjust_stock_position(\n",
    "                        date, stock, price, delta_stock, portfolio_value, daily_fee, realized_stocks_last_day)\n",
    "\n",
    "            # Calculate unrealized P/L\n",
    "            unrealized_stocks = sum((stock_prices.get(stock, 0) - self.stock_entry_prices.get(stock, 0)) * \n",
    "                                    self.stock_positions.get(stock, 0) for stock in self.stock_positions \n",
    "                                    if not np.isnan(stock_prices.get(stock, 0)))\n",
    "            unrealized_futures = ((vn30_price - (sum(self.entry_prices['VN30F1M']) / len(self.entry_prices['VN30F1M']) if self.entry_prices['VN30F1M'] else 0)) * \n",
    "                                 self.positions['VN30F1M'] * self.contract_size if self.positions['VN30F1M'] != 0 and not np.isnan(vn30_price) else 0)\n",
    "\n",
    "            # Update cumulative profits\n",
    "            self.cumulative_profit_stocks += profit_stocks_last_day\n",
    "            self.cumulative_profit_futures += profit_futures_last_day\n",
    "\n",
    "            # Record state only after estimation window\n",
    "            if day >= self.estimation_window:\n",
    "                portfolio_value = self.get_portfolio_value(vn30_price, stock_prices)\n",
    "                vn30f1m_notional = abs(self.positions['VN30F1M']) * vn30_price * self.contract_size if not np.isnan(vn30_price) else 0\n",
    "                abs_stocks = sum(self.stock_positions.get(stock, 0) * stock_prices.get(stock, 0) \n",
    "                                for stock in stock_prices if not np.isnan(stock_prices.get(stock, 0)))\n",
    "                positions = {'VN30F1M': self.positions['VN30F1M']}\n",
    "                positions.update(self.stock_positions)\n",
    "\n",
    "                self.asset_df.append({\n",
    "                    'Date': date, 'balance': portfolio_value, 'vn30f1m_notional': vn30f1m_notional, 'abs_stocks': abs_stocks,\n",
    "                    'cash': self.cash, 'positions': positions.copy()\n",
    "                })\n",
    "\n",
    "                vn30f1m_pct_change = (vn30_price - prev_vn30_price) / prev_vn30_price if prev_vn30_price is not None and prev_vn30_price != 0 and not np.isnan(vn30_price) else 0.0\n",
    "                total_stock_value = sum(self.stock_positions.get(stock, 0) * stock_prices.get(stock, 0) \n",
    "                                       for stock in stocks if not np.isnan(stock_prices.get(stock, 0)))\n",
    "                stock_pct_change = (sum(((stock_prices[stock] - prev_stock_prices[stock]) / prev_stock_prices[stock]) * \n",
    "                                       (self.stock_positions.get(stock, 0) * stock_prices.get(stock, 0) / total_stock_value)\n",
    "                                       for stock in stocks if prev_stock_prices[stock] is not None and prev_stock_prices[stock] != 0 and not np.isnan(stock_prices[stock]))\n",
    "                                   if total_stock_value > 0 else 0.0)\n",
    "\n",
    "                vn30f1m_weight = self.margin_posted / portfolio_value if portfolio_value > 0 else 0\n",
    "                weights = {'vn30f1m_weight': vn30f1m_weight}\n",
    "                weights.update({f'{stock}_weight': self.stock_positions.get(stock, 0) * stock_prices.get(stock, 0) / portfolio_value \n",
    "                                if portfolio_value > 0 and not np.isnan(stock_prices.get(stock, 0)) else 0 for stock in stocks})\n",
    "\n",
    "                self.detail_df.append({\n",
    "                    'Date': date,\n",
    "                    'balance': portfolio_value,\n",
    "                    'vn30f1m_notional': vn30f1m_notional,\n",
    "                    'vn30f1m_margin': self.margin_posted,\n",
    "                    'abs_stocks': abs_stocks,\n",
    "                    'abs_stocks_prev': abs_stocks_prev,  # Previous day's stock notional\n",
    "                    'cash': self.cash,\n",
    "                    'fee': daily_fee,\n",
    "                    'vn30f1m_pct_change': vn30f1m_pct_change,\n",
    "                    'stock_pct_change': stock_pct_change,\n",
    "                    'unrealized_stocks': unrealized_stocks,\n",
    "                    'unrealized_futures': unrealized_futures,\n",
    "                    'realized_stocks_last_day': realized_stocks_last_day,\n",
    "                    'realized_futures_last_day': realized_futures_last_day,\n",
    "                    'profit_stocks_last_day': profit_stocks_last_day,\n",
    "                    'profit_futures_last_day': profit_futures_last_day,\n",
    "                    'cumulative_profit_stocks': self.cumulative_profit_stocks,\n",
    "                    'cumulative_profit_futures': self.cumulative_profit_futures,\n",
    "                    **weights\n",
    "                })\n",
    "\n",
    "            # Calculate abs_stocks_prev for next iteration\n",
    "            abs_stocks_prev = sum(prev_stock_positions[stock] * prev_stock_prices[stock] \n",
    "                                 for stock in stocks if prev_stock_prices[stock] is not None and not np.isnan(prev_stock_prices[stock]))\n",
    "\n",
    "            self.trading_log.append({\n",
    "                'Date': date,\n",
    "                'VN30F1M_Traded': contracts_traded_vn30,\n",
    "                **{f'{stock}_Traded': shares_traded[stock] for stock in stocks}\n",
    "            })\n",
    "\n",
    "            # Update previous values\n",
    "            prev_positions['VN30F1M'] = self.positions['VN30F1M']\n",
    "            for stock in stocks:\n",
    "                prev_stock_positions[stock] = self.stock_positions.get(stock, 0)\n",
    "                prev_stock_prices[stock] = stock_prices.get(stock)\n",
    "            prev_vn30_price = vn30_price\n",
    "            self.prev_balance = portfolio_value\n",
    "\n",
    "        return (pd.DataFrame(self.asset_df).set_index('Date'),\n",
    "                pd.DataFrame(self.detail_df).set_index('Date'),\n",
    "                pd.DataFrame(self.trading_log).set_index('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_periods_df(vn30_stocks, start_date, end_date, window=60):\n",
    "    \"\"\"Generate a DataFrame of trading periods based on VN30 stock data, with the first start_date as specified.\n",
    "\n",
    "    Args:\n",
    "        vn30_stocks (pd.DataFrame): DataFrame with 'Date' index and 'Stock' column from get_vn30.\n",
    "        start_date (str): Desired start date for the first period in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date for the last period in 'YYYY-MM-DD' format.\n",
    "        window (int): Number of days to subtract from rebalancing date for start_date. Defaults to 60.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['stocks_list', 'start_date', 'end_date'],\n",
    "                      where the first start_date matches the input start_date.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If vn30_stocks is empty.\n",
    "    \"\"\"\n",
    "    if vn30_stocks.empty:\n",
    "        raise ValueError(\"No data found in vn30_stocks.\")\n",
    "\n",
    "    # Group stocks by date to get the list of stocks for each rebalancing date\n",
    "    grouped = vn30_stocks.groupby('Date')['Stock'].apply(list)\n",
    "    date_stock_pairs = [(date, stocks) for date, stocks in grouped.items()]\n",
    "\n",
    "    # Generate periods\n",
    "    periods = []\n",
    "    for i, (current_date, current_stocks) in enumerate(date_stock_pairs):\n",
    "        # Calculate start_date\n",
    "        start_date_calc = current_date - timedelta(days=window)\n",
    "\n",
    "        # Override the first start_date to match the input start_date\n",
    "        if i == 0:\n",
    "            period_start_date = pd.to_datetime(start_date)\n",
    "        else:\n",
    "            period_start_date = start_date_calc\n",
    "\n",
    "        # Determine end_date\n",
    "        if i < len(date_stock_pairs) - 1:\n",
    "            next_date = date_stock_pairs[i + 1][0]\n",
    "            end_date_calc = next_date - timedelta(days=1)\n",
    "        else:\n",
    "            end_date_calc = pd.to_datetime(end_date)  # Use the provided end_date for the last period\n",
    "\n",
    "        # Format dates as strings\n",
    "        start_date_str = period_start_date.strftime('%Y-%m-%d')\n",
    "        end_date_str = end_date_calc.strftime('%Y-%m-%d')\n",
    "\n",
    "        periods.append({\n",
    "            'stocks_list': current_stocks,  # No ETFs added\n",
    "            'start_date': start_date_str,\n",
    "            'end_date': end_date_str\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    periods_df = pd.DataFrame(periods)\n",
    "    return periods_df\n",
    "\n",
    "\n",
    "def run_backtest_for_periods(periods_df, futures='VN30F1M', etf_list=None, etf_included=False):\n",
    "    \"\"\"Run a backtest across all periods specified in periods_df.\n",
    "\n",
    "    Args:\n",
    "        periods_df (pd.DataFrame): DataFrame with ['stocks_list', 'start_date', 'end_date'] columns.\n",
    "        futures (str): Futures symbol for backtesting. Defaults to 'VN30F1M'.\n",
    "        etf_list (list): List of ETF ticker symbols to pass to DataHandler. Defaults to None.\n",
    "        etf_included (bool): Whether to include ETFs in DataHandler. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.DataFrame, pd.DataFrame)\n",
    "            - combined_returns_df: Time series of daily returns.\n",
    "            - combined_detail_df: Aggregated backtest details.\n",
    "    \"\"\"\n",
    "    all_returns_dfs = []\n",
    "    all_detail_dfs = []\n",
    "\n",
    "    # Run backtest for each period\n",
    "    for period_idx, period in periods_df.iterrows():\n",
    "        active_stocks = period['stocks_list']\n",
    "        start_date = period['start_date']\n",
    "        end_date = period['end_date']\n",
    "\n",
    "        print(f\"Running backtest for period {period_idx + 1}: {start_date} to {end_date} \"\n",
    "              f\"with stocks: {active_stocks}\")\n",
    "\n",
    "        # Initialize and run strategy with etf_list and etf_included\n",
    "        data_handler = DataHandler(\n",
    "            futures=futures,\n",
    "            stocks=active_stocks,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            etf_list=etf_list,\n",
    "            etf_included=etf_included\n",
    "        )\n",
    "        strategy = StatArbStrategy(data_handler)\n",
    "        strategy.run_strategy()\n",
    "        results_df_1, stock_price = strategy.get_results()\n",
    "\n",
    "        # Process results\n",
    "        results_df, positions_df, trading_log = process_results_df(\n",
    "            results_df_1, stock_price, stocks=active_stocks\n",
    "        )\n",
    "\n",
    "        # Run backtest\n",
    "        pm = PortfolioManager()\n",
    "        asset_df, detail_df,trading_log_df= pm.run_backtest(trading_log, stock_price)\n",
    "\n",
    "        # Compute and store returns\n",
    "        returns_df = asset_df['balance'].pct_change().fillna(0).to_frame(name='returns')\n",
    "        all_returns_dfs.append(returns_df)\n",
    "        all_detail_dfs.append(detail_df)\n",
    "\n",
    "    # Aggregate results\n",
    "    combined_returns_df = pd.concat(all_returns_dfs).sort_index()\n",
    "    combined_returns_df = combined_returns_df[~combined_returns_df.index.duplicated(keep='first')]\n",
    "\n",
    "    combined_detail_df = pd.concat(all_detail_dfs).sort_index()\n",
    "    combined_detail_df = combined_detail_df[~combined_detail_df.index.duplicated(keep='first')]\n",
    "\n",
    "    return combined_returns_df, combined_detail_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(returns_df, risk_free_rate=0.05, trading_day=252, freq=\"D\"):\n",
    "    \"\"\"Calculate Sharpe Ratio and Maximum Drawdown (MDD) for the strategy.\n",
    "\n",
    "    Args:\n",
    "        returns_df (pd.DataFrame): Portfolio returns with 'Date' index and 'returns' column.\n",
    "        risk_free_rate (float): Annual risk-free rate. Defaults to 0.05.\n",
    "        trading_day (int): Number of trading days per year for annualization. Defaults to 252.\n",
    "        freq (str): Frequency of the data ('D' for daily). Defaults to 'D'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with 'Sharpe Ratio' and 'MDD' for the strategy, rounded to 2 decimal places.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If returns_df is empty or missing the 'returns' column.\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if returns_df.empty:\n",
    "        raise ValueError(\"returns_df is empty.\")\n",
    "    \n",
    "    # Ensure returns_df has 'returns' column\n",
    "    if 'returns' not in returns_df.columns:\n",
    "        raise ValueError(\"returns_df must contain a 'returns' column.\")\n",
    "\n",
    "    # Ensure datetime index\n",
    "    returns_df = returns_df.copy()\n",
    "    returns_df.index = pd.to_datetime(returns_df.index)\n",
    "\n",
    "    # Rename 'returns' to 'Asset' for consistency\n",
    "    returns_df = returns_df.rename(columns={'returns': 'Asset'})\n",
    "\n",
    "    # Compute time length in years\n",
    "    start = returns_df.index[0].strftime('%Y-%m-%d')\n",
    "    end = returns_df.index[-1].strftime('%Y-%m-%d')\n",
    "    time_length = (datetime.strptime(end, '%Y-%m-%d') - datetime.strptime(start, '%Y-%m-%d')).days / 365.25\n",
    "\n",
    "    # Cumulative returns for the strategy\n",
    "    cum_rets = (1 + returns_df['Asset']).cumprod()\n",
    "    hpr_strategy = cum_rets.iloc[-1] - 1  # HPR for strategy\n",
    "\n",
    "    # Annualized return for Sharpe Ratio\n",
    "    annual_stock_return = (1 + hpr_strategy) ** (1 / time_length) - 1\n",
    "\n",
    "    # Volatility for Sharpe Ratio\n",
    "    std_strategy = returns_df['Asset'].std() * np.sqrt(trading_day)\n",
    "\n",
    "    # Sharpe Ratio (not in percentage)\n",
    "    sharpe_strategy = (annual_stock_return - risk_free_rate) / std_strategy if std_strategy != 0 else np.nan\n",
    "\n",
    "    # Maximum Drawdown\n",
    "    running_max_strategy = np.maximum.accumulate(cum_rets.dropna())\n",
    "    running_max_strategy[running_max_strategy < 1] = 1\n",
    "    drawdown_strategy = (cum_rets / running_max_strategy - 1)\n",
    "    max_drawdown_strategy = -drawdown_strategy.min()  # MDD as a positive decimal\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return sharpe_strategy, max_drawdown_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "# Main\n",
    "vn30_stocks=get_vn30('2021-06-01', '2025-01-10')\n",
    "vn30_stocks.index = pd.to_datetime(vn30_stocks.index)\n",
    "\n",
    "# Step 1: Generate the periods DataFrame with ETFs\n",
    "etfs_list = [ 'FUEVFVND', 'FUESSVFL', 'E1VFVN30', 'FUEVN100']\n",
    "start_date='2021-06-01'\n",
    "end_date='2025-01-01'\n",
    "periods_df = generate_periods_df(vn30_stocks, \n",
    "                                 start_date, \n",
    "                                 end_date, \n",
    "                                 window=60)\n",
    "# Step 2: Run the backtest using the periods DataFrame\n",
    "combined_returns_df, combined_detail_df = run_backtest_for_periods(\n",
    "    periods_df=periods_df,\n",
    "    futures='VN30F1M',\n",
    "    etf_list=etfs_list,\n",
    "    etf_included=False\n",
    ")\n",
    "sharpe,mdd=calculate_metrics(combined_returns_df, risk_free_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load data once at the start\n",
    "vn30_stocks = get_vn30('2021-06-01', '2025-01-10')\n",
    "vn30_stocks.index = pd.to_datetime(vn30_stocks.index)\n",
    "etfs_list = ['FUEVFVND', 'FUESSVFL', 'E1VFVN30', 'FUEVN100']\n",
    "start_date = '2021-06-01'\n",
    "end_date = '2025-01-01'\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest parameters to tune\n",
    "    estimation_period = trial.suggest_int('estimation_period', 30, 120, step=10)\n",
    "    clusters = trial.suggest_int('clusters', 2, 10)\n",
    "    min_trading_day = trial.suggest_int('min_trading_day', 20, 60, step=5)\n",
    "    significance_score = trial.suggest_float('significance_score', 0.01, 0.1, step=0.01)\n",
    "    s_score_tier = trial.suggest_float('s_score_tier', 0.5, 2.0, step=0.1)\n",
    "    \n",
    "    # Generate periods_df with suggested parameters\n",
    "    periods_df = generate_periods_df(\n",
    "        vn30_stocks,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        window=estimation_period,\n",
    "        clusters=clusters,  # Assumes this parameter is supported\n",
    "        min_trading_day=min_trading_day,  # Assumes this parameter is supported\n",
    "        significance_score=significance_score  # Assumes this parameter is supported\n",
    "    )\n",
    "    \n",
    "    # Run backtest with suggested parameters\n",
    "    combined_returns_df, combined_detail_df = run_backtest_for_periods(\n",
    "        periods_df=periods_df,\n",
    "        futures='VN30F1M',\n",
    "        etf_list=etfs_list,\n",
    "        etf_included=False,\n",
    "        s_score_tier=s_score_tier  # Assumes this parameter is supported\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics (maximize Sharpe ratio)\n",
    "    sharpe, mdd = calculate_metrics(combined_returns_df, risk_free_rate=0.05)\n",
    "    return sharpe\n",
    "\n",
    "# Create an Optuna study with SQLite storage for checkpointing\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    storage='sqlite:///optuna_study.db',\n",
    "    study_name='vn30_arbitrage_tuning',\n",
    "    load_if_exists=True,\n",
    "    pruner=optuna.pruners.MedianPruner()\n",
    ")\n",
    "# Optimize with a moderate number of trials\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best results\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(f\"Best Sharpe Ratio: {best_value}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Save all trials to CSV for progress tracking\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv('optuna_trials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
